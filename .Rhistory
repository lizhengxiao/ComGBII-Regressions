dtplot$y <- c(beta.mat[,1], beta.mat[,2], beta.mat[,3],
alpha.mat[,1], alpha.mat[,2],alpha.mat[,3], alpha.mat[,4],alpha.mat[,5], alpha.mat[,6])
dtplot$Parameters <- c(rep('beta0', Nsim),
rep('beta1', Nsim),
rep('beta2', Nsim),
rep('alpha0', Nsim),
rep('alpha1', Nsim),
rep('alpha2', Nsim),
rep('alpha3', Nsim),
rep('alpha4', Nsim),
rep('alpha5', Nsim))
dtplot$group <- as.factor(dtplot$Parameters)
labels = c(expression(paste(beta[0])),
expression(paste(beta[1])),
expression(paste(beta[2])),
expression(paste(alpha[0])),
expression(paste(alpha[1])),
expression(paste(alpha[2])),
expression(paste(alpha[3])),
expression(paste(alpha[4])),
expression(paste(alpha[5]))
)
dtbeta <- dtplot[Parameters %in% c('beta0','beta1', 'beta2')]
dtalpha <- dtplot[!Parameters %in% c('beta0','beta1', 'beta2')]
library(ggplot2)
dtbeta <- data.frame(dtbeta)
fig1basic <- ggplot(data = dtbeta, mapping = aes(y = y, x = Parameters, fill = Parameters)) +
theme_bw() + xlab('') + ylab('Estimates')
fig1 <- fig1basic +  geom_boxplot(outlier.colour = "red", outlier.shape = 1,
outlier.size = 1, varwidth = TRUE) +
scale_y_continuous(limits = c(0, 3),
breaks = seq(0, 3, by = 0.5),
expand = c(0, 0)) +
scale_x_discrete(labels = c(expression(paste(beta[0])),
expression(paste(beta[1])),
expression(paste(beta[2]))
)) +
scale_fill_discrete(name = "Parameters",
labels = c(expression(paste(beta[0])),
expression(paste(beta[1])),
expression(paste(beta[2]))
))
dtalpha <- data.frame(dtalpha)
fig2basic <- ggplot(data = dtalpha, mapping = aes(y = y, x = Parameters, fill = Parameters)) +
theme_bw() + xlab('') + ylab('Estimates')
fig2 <- fig2basic +  geom_boxplot(outlier.colour = "red", outlier.shape = 1,
outlier.size = 1, varwidth = TRUE) +
scale_y_continuous(limits = c(-8, 8),
breaks = seq(-8, 8, by = 2),
expand = c(0, 0)) +
scale_x_discrete(labels = c(expression(paste(alpha[1])),
expression(paste(alpha[2])),
expression(paste(alpha[3])),
expression(paste(alpha[4])),
expression(paste(alpha[5])),
expression(paste(alpha[6]))
)) +
scale_fill_discrete(name = "Parameters",
labels = c(expression(paste(alpha[1])),
expression(paste(alpha[2])),
expression(paste(alpha[3])),
expression(paste(alpha[4])),
expression(paste(alpha[5])),
expression(paste(alpha[6]))
))
library(patchwork)
fig0 <- fig1 + fig2 + plot_layout(ncol = 2)
fig0
library(gamlss) # load the gamlss package
library(Rsolnp) # load the Rsolnp package
set.seed(111) # set the seed for reproducibility
nsample <- 2000 # set the sample size
Nsim <- 20 # set the number of simulations
beta.mat <- matrix(0, nrow = Nsim, ncol = 3) # initialize the matrix for storing beta estimates
alpha.mat <- matrix(0, nrow = Nsim, ncol = 6) # initialize the matrix for storing alpha estimates
p1 <- 1; p2 <- 1.5; # set values for p1 and p2
tau1 <- 1.5; tau2 <- 2; # set values for tau1 and tau2
nu1 <- 2; nu2 <- 2; # set values for nu1 and nu2
sigma1 <- p1*tau1; sigma2 <- p2*tau2 # calculate sigma1 and sigma2
delta1 <- p1*nu1; delta2 <- p2*nu2 # calculate delta1 and delta2
pars1.true <- c(c(2, 0.5, 1),
log(c(p1, p2, tau1, tau2, nu1, nu2))) # true values of parameters
# Loop over simulations
for (j in 1:Nsim){
# Generate normally distributed random variables
x1 <- rnorm(n = nsample, mean = 0, sd = 1)
x2 <- rnorm(n = nsample, mean = 0, sd = 1)
# Create a model matrix with x1 and x2
X1 <- model.matrix( ~ x1 + x2)
# Get the number of columns in X1
k <- dim(X1)[2]
# Initialize the parameters with true values
pars <- pars1.true
# Get beta parameters from pars
beta <- pars[1:k]
# Calculate the expected value of mu2
mu2 <- exp(X1%*%beta)
# Calculate p1 and p2
p1 <- exp(pars[(k+1)]); p2 <- exp(pars[(k+2)])
# Calculate tau1 and tau2
tau1 <- exp(pars[(k+3)]); tau2 <- exp(pars[(k+4)])
# Calculate nu1 and nu2
nu1 <- exp(pars[(k+5)]); nu2 <- exp(pars[(k+6)])
# Check if p1 and nu1 are greater than 1
p1*nu1 - 1
# Check if p2 and nu2 are greater than 1
p2*nu2 - 1
# Initialize the simulated response variable
ysim <- 0
# Loop over the sample size
for(i in 1:nsample){
# Simulate response variable using the qcomGB2 function
ysim[i] <-  qcomGB2(p = runif(1, 0, 1), mu2 = as.numeric(mu2)[i],
p1 = p1, p2 = p2, nu1 = nu1, nu2 = nu2, tau1 = tau1, tau2 = tau2)
}
# Set y equal to the simulated response variable
y <- ysim
# Set X equal to the model matrix
X <- X1
# Use comGB2Reg.solnp to estimate the parameters
tryCatch({
mReg <- comGB2Reg.solnp(y = y, X = X, control = list(pars.init.n = 5,
rho = 2, tol.rel = 1.0e-4))
}, error = function(e) {
message('Return the next iteration')
})
# Get the estimates from mReg
estimates <- mReg$estimate
# Store beta estimates in the beta.mat matrix
beta.mat[j,] <- estimates[1:k]
# Store alpha estimates in the alpha.mat matrix
alpha.mat[j,] <- estimates[(k+1):(k+6)]
}
pars.true <- pars1.true
beta.true <- pars.true[1:3]
alpha.true <- pars.true[4:9]
# ggplot
library(data.table)
dtbeta <- data.frame(beta.mat)
colnames(dtbeta) <- c('beta0', 'beta1', 'beta2')
dtplot <- data.table()
dtplot$y <- c(beta.mat[,1], beta.mat[,2], beta.mat[,3],
alpha.mat[,1], alpha.mat[,2],alpha.mat[,3], alpha.mat[,4],alpha.mat[,5], alpha.mat[,6])
dtplot$Parameters <- c(rep('beta0', Nsim),
rep('beta1', Nsim),
rep('beta2', Nsim),
rep('alpha0', Nsim),
rep('alpha1', Nsim),
rep('alpha2', Nsim),
rep('alpha3', Nsim),
rep('alpha4', Nsim),
rep('alpha5', Nsim))
dtplot$group <- as.factor(dtplot$Parameters)
labels = c(expression(paste(beta[0])),
expression(paste(beta[1])),
expression(paste(beta[2])),
expression(paste(alpha[0])),
expression(paste(alpha[1])),
expression(paste(alpha[2])),
expression(paste(alpha[3])),
expression(paste(alpha[4])),
expression(paste(alpha[5]))
)
dtbeta <- dtplot[Parameters %in% c('beta0','beta1', 'beta2')]
dtalpha <- dtplot[!Parameters %in% c('beta0','beta1', 'beta2')]
library(ggplot2)
dtbeta <- data.frame(dtbeta)
fig1basic <- ggplot(data = dtbeta, mapping = aes(y = y, x = Parameters, fill = Parameters)) +
theme_bw() + xlab('') + ylab('Estimates')
fig1 <- fig1basic +  geom_boxplot(outlier.colour = "red", outlier.shape = 1,
outlier.size = 1, varwidth = TRUE) +
scale_y_continuous(limits = c(0, 3),
breaks = seq(0, 3, by = 0.5),
expand = c(0, 0)) +
scale_x_discrete(labels = c(expression(paste(beta[0])),
expression(paste(beta[1])),
expression(paste(beta[2]))
)) +
scale_fill_discrete(name = "Parameters",
labels = c(expression(paste(beta[0])),
expression(paste(beta[1])),
expression(paste(beta[2]))
))
dtalpha <- data.frame(dtalpha)
fig2basic <- ggplot(data = dtalpha, mapping = aes(y = y, x = Parameters, fill = Parameters)) +
theme_bw() + xlab('') + ylab('Estimates')
fig2 <- fig2basic +  geom_boxplot(outlier.colour = "red", outlier.shape = 1,
outlier.size = 1, varwidth = TRUE) +
scale_y_continuous(limits = c(-8, 8),
breaks = seq(-8, 8, by = 2),
expand = c(0, 0)) +
scale_x_discrete(labels = c(expression(paste(alpha[1])),
expression(paste(alpha[2])),
expression(paste(alpha[3])),
expression(paste(alpha[4])),
expression(paste(alpha[5])),
expression(paste(alpha[6]))
)) +
scale_fill_discrete(name = "Parameters",
labels = c(expression(paste(alpha[1])),
expression(paste(alpha[2])),
expression(paste(alpha[3])),
expression(paste(alpha[4])),
expression(paste(alpha[5])),
expression(paste(alpha[6]))
))
library(patchwork)
fig0 <- fig1 + fig2 + plot_layout(ncol = 2)
fig0
fig0
fitRegComGBII <- function(y, X, family = c('comGB2'),
control = list(print_level = 1,
pars.seed = 113,
pars.init.n = 5,
tol.rel = 1.0e-8,
rho = 0.1)){
if (family == 'comGB2'){
mod <- comGB2Reg.solnp(y = y, X = X,
control = control)
} else if(family == 'GBIIG'){
mod <- GBIIGReg.solnp(y = y, X = X,
control = control)
}  else if(family == 'BIIG'){
mod <- BIIGReg.solnp(y = y, X = X,
control = control)
}  else if(family == 'BG'){
mod <- BGReg.solnp(y = y, X = X,
control = control)
}  else if(family == 'IBG'){
mod <- IBGReg.solnp(y = y, X = X,
control = control)
}  else if(family == 'PG'){
mod <- PGReg.solnp(y = y, X = X,
control = control)
} else if(family == 'IPG'){
mod <- IPGReg.solnp(y = y, X = X,
control = control)
}
return(mod)
}
# 1. comGB2 regression model -------------------
library(Rsolnp) # Load the Rsolnp package for optimization
# This is R code for estimating a regression model using the comGB2 distribution.
# The comGB2 distribution is a seven-parameter distribution and is often used to model data with heavy tails and skewness.
# The code starts by defining a log-likelihood function (LLcomGB2.Reg) that takes a set of parameters as input and returns the negative log-likelihood of the data given those parameters.
# The function uses the dcomGB2 function to calculate the log-likelihood of the comGB2 distribution given the data, the predicted values from the regression model (mu2), and the parameter values.
# The code then defines a function (ieqnPars) that imposes inequality constraints on the parameters. These constraints ensure that certain parameters (e.g., delta1 and delta2) are positive. The constraints are implemented using the solnp function, which is a nonlinear optimization solver that allows for inequality constraints.
# The code sets the lower and upper bounds for the parameters using the LB and UB vectors. It then initializes the parameter vector (pars) to the values in pars.int and uses the solnp function to find the parameter values that minimize the negative log-likelihood. The resulting parameter estimates are stored in the mReg$pars vector.
# Finally, the code extracts the estimated beta coefficients (which are the first k elements of the pars vector) and the estimated comGB2 distribution parameters (which are the last six elements of the pars vector). These estimates are returned as a single vector (est).
comGB2Reg.solnp <- function(y, X, control = list(print_level = 1,
pars.seed = 113,
pars.init.n = 5,
tol.rel = 1.0e-8,
rho = 0.1)){
# y: observations
# X: design matrix
print_level <- control$print_level # Get print_level from the control list
n.init <- control$pars.init.n # Get the number of groups for initialization parameters
pars.seed <- control$pars.seed # Get the pars.seed from the control list
tol.rel <- control$tol.rel # Get the relative tolerance from the control list
rho <- control$rho # Get the rho from the control list
k <- dim(X)[2] # Get the number of parameters
mod.init <- pars.initialization(y = y, X = X) # Get the initial values of parameters using the pars.initialization function
beta.init <- mod.init$beta.init # Get the initial value of beta
# p1, p2, sigma1, sigma2, delta1, delta2
# alpha1, alpha2, alpha3, alpha4, alpha5, alpha6
# sigma <- p*tau
# delta <- p*nu
# for instance,
# sigma1 <- p1*tau1; sigma2 <- p2*tau2
# delta1 <- p1*nu1; delta2 <- p2*nu2
LLcomGB2.Reg <-  function(pars) {
# Define a function for computing the log-likelihood of the comGB2 model with parameters beta, alpha1, alpha2, alpha3, alpha4, alpha5, and alpha6
k <- dim(X)[2] # Get the number of parameters
beta <- pars[1:k] # Get beta from the parameter vector
mu2 <- exp(X%*%beta) # Calculate mu2 based on the formula
p1 <- exp(pars[(k+1)]); # Get p1 from the parameter vector
p2 <- exp(pars[(k+2)]); # Get p2 from the parameter vector
sigma1 <- exp(pars[(k+3)]) # Get sigma1 from the parameter vector
sigma2 <- exp(pars[(k+4)]) # Get sigma2 from the parameter vector
delta1 <- exp(pars[(k+5)]) # > 1; Get delta1 from the parameter vector
delta2 <- exp(pars[(k+6)]) # > 1; Get delta2 from the parameter vector
nu1 <- (delta1)/p1; tau1 <- sigma1/p1 # Calculate nu1 and tau1 based on the formulas
nu2 <- (delta2)/p2; tau2 <- sigma2/p2 # Calculate nu2 and tau2 based on the formulas
loglike <- dcomGB2(y = y, # Compute the log-likelihood of the comGB2 model based on the given parameters
mu2 = as.vector(mu2),
p1 = p1,
p2 = p2, tau1 = tau1, tau2 = tau2, nu1 = nu1, nu2 = nu2,
log = T)
ll <- -sum(loglike)
if(is.na(ll) | is.infinite(ll)) ll <- 100000000000
return(ll)
}
ieqnPars <- function(pars){
k <- dim(X)[2]
p1 <- exp(pars[k+1])
p2 <- exp(pars[k+2])
sigma1 <- exp(pars[(k+3)])
sigma2 <- exp(pars[(k+4)])
delta1 <- exp(pars[(k+5)]) # > 1
delta2 <- exp(pars[(k+6)]) # > 1
z2 <- pars[(k+5)] # >= 0
z3 <- pars[(k+6)] # >= 0
return(c(z2, z3))
}
alpha.init.mat <- matrix(0, nrow = 6, ncol = n.init)
row.names(alpha.init.mat) <- c('p1', 'p2',
'sigma1', 'sigma2',
'delta1', 'delta2')
opt.result <- rep(0, n.init) # Define the vector for storing optimization results
mReg.list <- list()
set.seed(pars.seed)
for (j in 1:n.init) {
# Generate random numbers
random_nums <- rnorm(6, 0, 1)
# random_nums <- runif(6, min = -2, max = 2)
# Determine if the conditions are met
while ((random_nums[5] < 0) | (random_nums[6] < 0)) {
# If it does not meet the requirements, regenerate the random number
random_nums <- rnorm(6, 0, 1)
# random_nums <- runif(6, min = -2, max = 2)
}
alpha.init <- random_nums
alpha.init.mat[, j] <- alpha.init
pars.int <- c(beta.init, alpha.init)
tryCatch({
suppressWarnings(
mReg <- solnp(pars = pars.int,
fun =  LLcomGB2.Reg,
ineqfun = ieqnPars,
ineqLB = c(0, 0),
ineqUB = c(10, 10),
LB = c(rep(-10, times = dim(X)[2]), rep(-10, times = 6)),
UB = c(rep(10, times = dim(X)[2]), rep(10, times = 6)),
control = list(rho = rho,
tol = tol.rel,
trace = print_level))
)
}, error = function(e) {
# The code to handle errors
# You can use the message() function to output error messages
message('Perform the next parameter initialization')
})
mReg.list[[j]] <- mReg
opt.result[j] <- mReg$values[length(mReg$values)]
}
best.alpha.init <- as.vector(alpha.init.mat[, which.min(opt.result)])
pars.int <- c(beta.init, best.alpha.init)
mReg <- mReg.list[[which.min(opt.result)]]
est <- mReg$pars
NLL <- mReg$values[length(mReg$values)]
npars <- k + 6
AIC <- 2*NLL + 2*npars
BIC <- 2*NLL + npars*log(length(y))
names(est)[1:k] <- paste0('beta', 0:(k-1))
names(est)[(k+1):(npars)] <- paste0('alpha', 1:6)
out <- list(estimate = est,
Hessian = mReg$hessian,
NLL = NLL,
AIC = AIC, BIC = BIC,
npars = npars)
return(out)
}
# This function calculates and returns a summary table of the estimated parameters for the comGB2 model. The input parameter model is an object returned by the comGB2 function. The class parameter can be set to either 'original' or 'transformed' to indicate whether to display the estimates and standard errors in the original or transformed scale.
# The function first extracts the parameter estimates and standard errors from the model object, and then calculates the z-values and p-values for each parameter. The z-value is calculated as the ratio of the estimate to the standard error, and the p-value is calculated using a two-sided normal distribution test.
# If class is set to 'original', the function formats the output table to display the estimates, standard errors, z-values, and p-values for the beta and alpha parameters. If class is set to 'transformed', the function additionally calculates the variance-covariance matrix of the transformed parameters and displays the estimates, standard errors, z-values, and p-values for the transformed parameters.
# The output of the function is a list with one element named summarytable, which contains the summary table as a data frame. The row names of the table correspond to the parameter names.
summary.comGB2 <- function(model, class = c('original',
'transformed')){
pars <- model$estimate
npars <- length(pars)
k <- npars - 6
beta <- pars[1:k]
p1 <- exp(pars[(k+1)]);
p2 <- exp(pars[(k+2)]);
sigma1 <- exp(pars[(k+3)])
sigma2 <- exp(pars[(k+4)])
delta1 <- exp(pars[(k+5)]) # > 1
delta2 <- exp(pars[(k+6)]) # > 1
nu1 <- (delta1)/p1; tau1 <- sigma1/p1
nu2 <- (delta2)/p2; tau2 <- sigma2/p2
Hessian <- model$Hessian[3:(npars + 2), 3:(npars + 2)]
cov <- (solve(Hessian))
se <- sqrt(diag(solve(Hessian)))                 ## standard error
if(class == 'original'){
est <- c(beta, log(c(p1, p2, sigma1, sigma2, delta1, delta2)))
zvalue <- est/se                                      ##  Z statistic
pvalue <- ifelse(zvalue>=0, pnorm(zvalue, lower=F)*2, pnorm(zvalue)*2)           ## p value
summarytable <- data.frame(estimates = est,
se = se,
zvalue = zvalue,
pvalue = pvalue)
row.names(summarytable)[1:k] <- paste0('beta', 0:(k-1))
row.names(summarytable)[(k+1):length(pars)] <- paste0('alpha', 1:6)
} else {
var.p1 <- p1*cov[1,1]*p1
var.p2 <- p2*cov[2,2]*p2
var.tau1 <- t(c(-tau1, tau1))%*%cov[c(1,3), c(1,3)]%*%(c(-tau1, tau1))
var.tau2 <- t(c(-tau2, tau2))%*%cov[c(2,4), c(2,4)]%*%(c(-tau2, tau2))
var.nu1 <- t(c(-nu1, nu1))%*%cov[c(1,5), c(1,5)]%*%(c(-nu1, nu1))
var.nu2 <- t(c(-nu2, nu2))%*%cov[c(2,6), c(2,6)]%*%(c(-nu2, nu2))
se <- c(se[1:k], sqrt(c(var.p1, var.p2,
var.tau1, var.tau2,
var.nu1, var.nu2)))
est <- c(beta, (c(p1, p2, tau1, tau2, nu1, nu2)))
zvalue <- est/se                                            ##  Z statistic
pvalue <- ifelse(zvalue>=0, pnorm(zvalue, lower=F)*2, pnorm(zvalue)*2)           ## p value
summarytable <- data.frame(estimates = est,
se = se,
zvalue = zvalue,
pvalue = pvalue)
row.names(summarytable)[1:k] <- paste0('beta', 0:(k-1))
row.names(summarytable)[(k+1):length(pars)] <- c('p1', 'p2', 'tau1', 'tau2', 'nu1', 'nu2')
}
out <- list(summarytable = summarytable)
return(out)
}
setwd("E:/ComGBII-Regressions")
source('functions-comGB2-distribution.r', local = TRUE)
source('functions-fit-comGBIIReg.r', local = TRUE)
source('1-comGB2-model-solnp.r', local = TRUE)
source('2-GBIIG-model-solnp.r', local = TRUE)
source('3-BIIG-model-solnp.r', local = TRUE)
source('4-BG-model-solnp.r', local = TRUE)
source('5-IBG-model-solnp.r', local = TRUE)
source('6-PG-model-solnp.r', local = TRUE)
source('7-IPG-model-solnp.r', local = TRUE)
source('functions-fit-comGBIIReg.r', local = TRUE)
source('functions-comGB2-distribution.r', local = TRUE)
control = list(print_level = 1,
pars.seed = 113,
pars.init.n = 5,
tol.rel = 1.0e-8,
rho = 0.1)
library(gamlss)
library(data.table)
library(nloptr)
library(gamlss)
library(numDeriv)
library(SMPracticals)
data("danish")
data <- data.table(danish)
y <- as.numeric(data$danish)
summary(y); mean(y); sd(y)
x <- sort(y)
q <- 1:length(x)
qlevel <- c(0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 0.999, 0.9999)
y = y
X = model.matrix( ~ 1, data = data.frame(y = y))
control = list(print_level = 1,
pars.seed = 113,
pars.init.n = 5,
tol.rel = 1.0e-8,
rho = 0.1)
source('1-comGB2-model-solnp.r', local = TRUE)
source('2-GBIIG-model-solnp.r', local = TRUE)
source('3-BIIG-model-solnp.r', local = TRUE)
source('4-BG-model-solnp.r', local = TRUE)
source('5-IBG-model-solnp.r', local = TRUE)
source('6-PG-model-solnp.r', local = TRUE)
source('7-IPG-model-solnp.r', local = TRUE)
source('functions-fit-comGBIIReg.r', local = TRUE)
source('functions-comGB2-distribution.r', local = TRUE)
# =========================================================
# model fitting
# =========================================================
mycontrol <- list(pars.seed = 3223,
pars.init.n = 5, rho = 0.1,
tol.rel = 1.0e-8)
m.comGB2 <- comGB2Reg.solnp(y = y, X = X, control = mycontrol)
summary.comGB2(model = m.comGB2, class = 'transformed')
summary.comGB2(model = m.comGB2, class = 'transformed')
m.GBIIG <- GBIIGReg.solnp(y = y, X = X, control = mycontrol)
summary.GBIIG(model = m.GBIIG, class = 'transformed')
m.BIIG <- BIIGReg.solnp(y = y, X = X, control = mycontrol)
summary.BIIG(model = m.BIIG, class = 'original')
summary.BIIG(model = m.BIIG, class = 'transformed')
m.BG <- BGReg.solnp(y = y, X = X,  control = mycontrol)
summary.BG(model = m.BG, class = 'transformed')
m.IBG <- IBGReg.solnp(y = y, X = X, control = mycontrol)
summary.IBG(model = m.IBG, class = 'transformed')
m.PG <- PGReg.solnp(y = y, X = X,  control = mycontrol)
summary.PG(model = m.PG, class = 'transformed')
m.IPG <- IPGReg.solnp(y = y, X = X, control = mycontrol)
summary.IPG(model = m.IPG, class = 'transformed')
family.name <- c('comGB2', 'GBIIG',
'BIIG', 'BG', 'IBG', 'PG', 'IPG')
m.name <- paste0('m.', family.name)
method.name <- paste0('summary.', family.name)
results.mat  <- se.mat <- matrix(0, nrow = 7, ncol = 4 + 7)
rownames(results.mat) <- rownames(se.mat) <- m.name
colnames(results.mat) <- colnames(se.mat) <- c('log(mu2)',
'p1', 'p2', 'tau1', 'tau2',
'nu1', 'nu2',
'npars','NLL','AIC','BIC')
for(i in 1:7){
m.temp <- get(m.name[i])
est.table <- do.call(what = get(method.name[i]),
args = list(model = m.temp, class = 'transformed'))
m.est <- est.table$summarytable[,1]
m.se <- est.table$summarytable[,2]
results.mat[i,] <- c(m.est,
m.temp$npars,
m.temp$NLL,  m.temp$AIC, m.temp$BIC)
se.mat[i,] <- c(m.se,
m.temp$npars,
m.temp$NLL,  m.temp$AIC, m.temp$BIC)
}
round(results.mat[order(results.mat[,2+7]), ], 3) # NULL sorting
round(results.mat[order(results.mat[,3+7]), ], 3) # AIC sorting
results.mat[order(results.mat[,4+7]), ] # BIC sorting
results.mat
